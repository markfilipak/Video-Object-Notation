# Video-Object-Notation
Use a notation to model source video and target video. A notation interpreter (proposed) handles the details.

Link to live page: https://markfilipak.github.io/Video-Object-Notation/

Changes:
<TABLE BORDER=0 CELLSPACING=0 CELLPADDING=0>
<TR><TD style="vertical-align:top">2022-08-26&nbsp;</TD>
    <TD>"<B>10-to-8-detelecine</B>" renamed "<B>5-to-4-detelecine</B>"<BR>
        "<B>50-to-48-detelecine</B>" renamed "<B>25-to-24-detelecine</B>"<BR>
        Generations (global), base on full images, not halfpics.
        </TD></TR>
<TR><TD style="vertical-align:top">2022-08-25&nbsp;</TD>
    <TD><B>Audio Conversions</B><BR>
        "<B>Giving names to commonly encountered cinema sources</B>" renamed "<B>Giving names to commonly found media sources</B>"<BR>
        <B>Giving names to commonly found media sources</B>, moved</TD></TR>
<TR><TD style="vertical-align:top">2022-08-23&nbsp;</TD>
    <TD><B><I>Extra Credit</I></B></TD></TR>
<TR><TD style="vertical-align:top">2022-08-22&nbsp;</TD>
    <TD>Spelling corrections (global)<BR>
        <B>Look-seen notation & scanner</B><BR>
        'look'-'seen' renamed look-seen (global)</TD></TR>
<TR><TD style="vertical-align:top">2022-08-19&nbsp;</TD>
    <TD><B>Tokens that cross stride boundaries: $</B><BR>
        <B>Look-seen notation & scanner</B>, If <TT>(</TT><I>look</I><TT>)</TT><BR>
        <B>Look-seen notation & scanner</B>, <TT>(</TT><I>unseen</I><TT>)</TT></TD></TR>
<TR><TD style="vertical-align:top">2022-08-17&nbsp;</TD>
    <TD><B>Look-seen notation & scanner</B><BR>
        Corrections/clarifications (global)</TD></TR>
<TR><TD style="vertical-align:top">2022-08-13&nbsp;</TD>
    <TD>Rewritten to target a video-savvy audience<BR>
        Added support for methods (e.g., pixel methods)</TD></TR>
</TABLE><BR>
